{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "*Objective of this sheet*\n",
    "</div>\n",
    "\n",
    "\n",
    "* Introduction to Groupby\n",
    "* Dealing with multiindex\n",
    "* Renaming a multindex\n",
    "* How to use the transpose\n",
    "* Swaping (swaplevel)the multindex\n",
    "* Stacking\n",
    "* Getting the random sample out of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "fortune = pd.read_csv('fortune1000.csv', index_col = 'Rank')\n",
    "fortune.iloc[0:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple company falls into a same sector.   - for groupby sector would be handy.\n",
    "\n",
    "fortune.groupby('Sector')      # 0x10962a128> is just the memory\n",
    "\n",
    "# It will look into all the values in the Sector columns.\n",
    "# Pandas will loop through all the dataset and  collect all the rows that falls onto that sector.\n",
    "#  It will repeat that for every single structure that it sees here. Once it has all these dataframes, each \n",
    "#  representing different sector. It will thenbundle them up and store them in a larger object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors = fortune.groupby('Sector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going ahead with the first operation of Groupby:\n",
    "len(fortune)      # it gives the number of rows in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sectors)      # There are 21 unique sectors \n",
    "\n",
    "# Can we prove the above point with some function that we have covered in one dimension - nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors.size()     # we will get the Series where the index represents the Sectors or the groupings\n",
    "                   # and the values represents the number of rows in each of those groupings or dataframes\n",
    "    \n",
    "# This should remind us of the value_counts methods that we saw in 1Dimensional case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors.first()    #we will get the very first row of all the unique Sectos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors.get_group('Energy')    # it is getting a subset, basically pulling all the rows where we have energy.\n",
    "\n",
    "# Why I feel it is powerful? If we were wanting to create seperate sector values as different dataframes\n",
    "# fortune[fortune['Sector'] == 'Energy'], it will take 21 lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods on the Groupby Object and DataFrame Columns\n",
    "sectors.max()     # Will return the last occurance of the left most column(i.e Company) on the basis of Sector.\n",
    "sectors.min()     # the row that has occured for the first time in a column\n",
    "sectors.sum()     # now sum requires the integers or float column. here we get at the aggregate level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now suppose we want to aggregate on two columns, in that case:\n",
    "sectors[['Revenue', 'Profits']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grouping by multiple columns:\n",
    "# Some initial things will chage in this case:  The number of varibales in features will increase.\n",
    "\n",
    "sectors = fortune.groupby(['Sector', 'Industry'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us see how is the sector distributed.\n",
    "\n",
    "sectors.size()   # It is seen as multiindex series. Within each sector the combination of industries are available.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors.sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## agg() method.\n",
    "# Through agg method we can select the columns and then what method we want to perform on them.\n",
    "sectors.agg({'Revenue' :'sum', \n",
    "            'Profits' : 'sum',\n",
    "            'Employees' : 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to each column, let say we want to apply multiple functions.\n",
    "sectors.agg(['size', 'sum', 'mean'])\n",
    "\n",
    "# agg method is an aggregator, it accepts either a dictionary where we specify what we want to aggregate\n",
    "# each column by. and also it can take the lists where it pplies to every single column.\n",
    "\n",
    "# and ofcourse we can mix them, can you please help me on this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Multiindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigmac = pd.read_csv('bigmac.csv', parse_dates = ['Date'])\n",
    "# The price of a bigmac is taken as an economic indicator of a country performance.\n",
    "bigmac.iloc[0:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigmac.info()  # there are no null values, so we are good with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how we have created a single index dataframe\n",
    "bigmac.set_index('Date')    # In order to make this shift permanent we have to use inplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us set two columns as an index:\n",
    "bigmac.set_index(keys = ['Date', 'Country'], inplace = True)  #date is at parent level, cuz we passed it first.\n",
    "\n",
    "bigmac.head(3)\n",
    "# Best practice: The column that has the least values shold serve as the outer layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigmac.sort_index()   # intially will sort on the basis of the date, later will sort country wise alphabetically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigmac.index    #if we will add names, it will show both the inner and outer index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the level values of the index:\n",
    "bigmac.index.get_level_values(0)     # by writng o, we will get the parentlevel information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the index.\n",
    "bigmac.index.set_names(['Day', 'Location'])       #at last we can see the day and location\n",
    "# we can use the inplace parameter to make the change permanent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have to mention both the values, becasue the operation takes place value wise. \n",
    "bigmac.index.set_names(['Date', 'Location'], inplace = True)   # so the names are overwritten here.\n",
    "\n",
    "bigmac.iloc[14:17, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to sort the multiIndex.  Here the difference is the we have to select the list. As it is multiindex.\n",
    "\n",
    "bigmac.sort_index(ascending= [True,False], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to extract rows from a multiIndex DataFrame.\n",
    "# we want to extract the value from the date index.\n",
    "\n",
    "bigmac.loc[(\"2010-01-01\", 'Brazil'), 'Price in US Dollars']     \n",
    "\n",
    " # we have to pass a tuple here, lists does not work here. \n",
    "# so the first argument hs to be tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transpose on multiindex. We have now the opposite of first. Now we have 652 columns & a row.\n",
    "bigmac = bigmac.transpose()   #it doe not have the parameter by name , inplace. Hence assigning the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigmac.loc['Price in US Dollars', ('2016-01-01', 'Denmark')]         # To get the rate in Denmark on a particular date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the dataset, this time fresh one to carry the further steps.\n",
    "bigmac = pd.read_csv('bigmac.csv', parse_dates = ['Date'], index_col = ['Date', 'Country'])\n",
    "bigmac.sort_index(inplace = True)\n",
    "bigmac.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Swaping the index, as we are just having two index so directly we can swap between them.\n",
    "bigmac.swaplevel().head(4)      # we just have two levels, hence no need to pass any argument.\n",
    "\n",
    "# we cann see below the swapping has taken place.\n",
    "# again here we have no inplace parameters, hence I have to assign it to the new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## From now onwards we will be using the new datasets.\n",
    "\n",
    "world = pd.read_csv('worldstats.csv', index_col = ['country', 'year'])\n",
    "world.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## the stack method: \n",
    "\n",
    "world.stack()\n",
    "\n",
    "# what can we observe?\n",
    "# We have doubled the dataset from the rows perspective.\n",
    "# just halved the dataset from the column siede\n",
    "# In pandas term it has now got into one dimensional object.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If in stacking we are not comfortable with the Series, then we can just transform it to dataframe\n",
    "world.stack().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salesman (data can be used for this one.)\n",
    "# In pivot method: the columns shold have most number of unique values.\n",
    "# condensing the dataframe by aligning the common values.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the Random Sample with the sample() method\n",
    "world.sample()    #by default will give just one row.\n",
    "\n",
    "# It just generated one random sample out of the dateframe. Just cuz this is random the output will differ every run.\n",
    "# major parameters : frac stands for fraction, it tells the % of data we want as an output. .25 will give 25% of data.\n",
    "# axis can be handy with the relevance of the rows or columns.\n",
    "# It is very handy, you will discover this during the ML sessions. Just remember this random method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
